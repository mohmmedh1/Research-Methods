\# Unit 9 ‚Äì Validity and Generalisability in Research



\## 1. Overview

This unit examined the core concepts of \*\*validity\*\*, \*\*reliability\*\*, and \*\*generalisability\*\* ‚Äî three interdependent dimensions that determine the credibility of research findings.  

As Saunders, Lewis, and Thornhill (2023) explain, reliability ensures consistency in measurement, validity confirms that the study measures what it intends to measure, and generalisability reflects whether the findings can be applied beyond the sampled context.



In cybersecurity research, these principles are vital for ensuring that analytical outcomes ‚Äî such as breach statistics or user-behaviour patterns ‚Äî can be trusted and meaningfully extended to other institutional settings.



---



\## 2. Learning Focus

\- Introduce \*\*validity\*\*, \*\*reliability\*\*, and \*\*generalisability\*\* in quantitative and qualitative contexts.  

\- Apply statistical testing to evaluate relationships and effect sizes.  

\- Assess sampling frames and population coverage to ensure external validity.  

\- Strengthen research transparency and replicability through sound analytical design.



---



\## 3. Charts Worksheet ‚Äì Results and Interpretation

The \*\*Unit 9 Charts Worksheet\*\* applied inferential techniques to evaluate dataset validity and generalisability using three datasets: \*Heather.xlsx\*, \*Superplus.xlsx\*, and \*Brandprefs.xlsx\*.



\### 3.1 Exercise 9.1D ‚Äì \*Heather (Location √ó Prevalence)\*

| | Location A | Location B |

|---|---|---|

| Sparse | 22 | 14 |

| Abundant | 26 | 10 |



\- \*\*œá¬≤ = 0.562\*\*, \*\*df = 1\*\*, \*\*p = 0.45325\*\*  

\- \*\*Decision (Œ± = 0.05):\*\* Fail to reject H‚ÇÄ.  

&nbsp; No statistically significant association between location and prevalence.  

&nbsp; \*\*Validity note:\*\* Differences may reflect random sampling error; replicating with a larger sample would increase power.



---



\### 3.2 Exercise 9.2D ‚Äì \*Superplus (Sex √ó Income)\*

| Sex | n | Mean | Median | SD |

|------|---|-------|--------|------|

| Female | 60 | 44.23 | 38.15 | 13.79 |

| Male | 60 | 52.91 | 52.05 | 15.27 |



\- \*\*t = 3.268\*\*, \*\*p = 0.00142\*\*, \*\*Cohen‚Äôs d = 0.597\*\* (medium‚Äìlarge)  

\- \*\*Decision (Œ± = 0.05):\*\* Reject H‚ÇÄ.  

&nbsp; Mean income differs significantly between sexes.  

&nbsp; \*\*Generalisability note:\*\* Balanced sampling suggests findings extend to similar populations, but contextual factors (industry, region) should be considered.



---



\### 3.3 Exercise 9.3B ‚Äì \*Brandprefs (Area √ó Brand)\*

| Area | Brand A | Brand B | Other |

|-------|----------|----------|--------|

| 1 | 11 | 17 | 42 |

| 2 | 19 | 30 | 41 |



\- \*\*œá¬≤ = 3.293\*\*, \*\*df = 2\*\*, \*\*p = 0.19276\*\*  

\- \*\*Decision (Œ± = 0.05):\*\* Fail to reject H‚ÇÄ.  

&nbsp; No significant difference in brand preference by area.  

&nbsp; \*\*Validity/generalisation note:\*\* Sampling frames must capture all relevant areas to avoid coverage bias.



---



\## 4. Data Visualisation with Power BI

A complementary activity, \*\*‚ÄúPracticing Business Visualisation with Power BI,‚Äù\*\* introduced practical dashboard-design principles aligned with Microsoft Power Platform analytics standards.  

This session emphasised:

\- Structuring analytical reports using consistent layout and navigation.  

\- Selecting visual types (bar, line, KPI, card, slicer) aligned with the data story.  

\- Applying filters and slicers responsibly to prevent misinterpretation.  

\- Designing accessible and interactive dashboards to improve data transparency.



\*\*Application:\*\*  

I replicated one exercise using sample incident data from my cybersecurity context, creating a Power BI dashboard displaying \*incident count by source\*, \*mean response time\*, and \*risk severity trends\*.  

This experience illustrated how \*\*data validity and visual integrity\*\* are intertwined ‚Äî poor filtering or misleading scaling can distort conclusions, just as invalid sampling can in statistical research.



---



\## 5. Reflection ‚Äì Validity \& Generalisability

The worksheet and Power BI tasks reinforced that \*\*significant findings strengthen internal validity\*\*, while \*\*sampling design and replication underpin external validity\*\*.  

For instance, the Superplus dataset‚Äôs significant income gap demonstrates measurable generalisability, whereas non-significant results in Heather and Brandprefs require cautious interpretation.  



The Power BI dashboard exercise highlighted that ethical visualisation practices ‚Äî avoiding bias, exaggeration, or omission ‚Äî are extensions of research validity principles.  

This parallel is especially relevant in cybersecurity analytics, where dashboards drive operational decisions and must maintain \*\*data accuracy, clarity, and reproducibility\*\*.



---



\## 6. Evidence

\- üìÑ \[Unit 9 ‚Äì Validity and Generalisability (Worksheet PDF)](unit07\_08\_09/Unit9\_Validity\_and\_Generalisabi....pdf)  

\- üìä Power BI Exercise: \*Practicing Business Visualisation with Power BI\* (University of Essex Online Learning Path)



---



\## 7. References

\- Business Research Methodology (BRM). (2021) \*Qualitative Data Analysis.\*  

\- Microsoft. (2023) \*Design Effective Reports in Power BI.\*  

\- Purdue University. (2023) \*Basic Inferential Statistics: Theory and Application.\*  

\- Saunders, M., Lewis, P. and Thornhill, A. (2023) \*Research Methods for Business Students\* (9th edn). Pearson Education.  



