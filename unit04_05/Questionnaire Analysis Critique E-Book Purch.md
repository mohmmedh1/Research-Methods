Questionnaire Critique: E-Book Purchasing and Recommendation System

1. Purpose and Relevance

The questionnaire effectively targets user experience with an e-book purchasing and recommendation system. The inclusion of behavioural (e.g., Q1–Q3) and attitudinal (Q4–Q8) items allows for mixed data analysis. However, some questions could be better aligned to the stated aim—evaluating usability—by focusing more directly on system functionality, trust, and satisfaction metrics rather than general spending patterns.

2. Format Evaluation

Strengths:

The questionnaire is short and uses closed-ended questions, reducing fatigue.

Instructions clearly explain anonymity and purpose, enhancing validity.

Weaknesses:

Skip logic (Q1 → Q3) is not automated; respondents may misinterpret it.

The numeric satisfaction scale (Q4) lacks consistent visual alignment (e.g., Likert grid).

No progress indication or estimated completion time.

Improvement:
Digitally implement branching logic, use consistent scale formatting, and add a short completion time estimate (e.g., “Takes less than 3 minutes”).

3. Question Content Analysis
Question	Analysis	Improvement
Q1–Q2 (purchase frequency & spending)	Establish baseline experience but not directly tied to usability goals.	Merge into one question or move to a demographic section.
Q3 (frequency)	Logical but categories overlap (“Never” vs. “1 time per month”).	Ensure mutually exclusive categories.
Q4 (satisfaction)	Simple 5-point scale is clear but lacks context on what “system” means.	Add descriptor: “Overall, how satisfied are you with the e-book recommendation interface?”
Q5 (agreement items)	Measures perception of usefulness and effectiveness but risks acquiescence bias.	Include reverse-worded statements, e.g., “The recommendation function often gives irrelevant results.”
Q6 (providers used)	Comprehensive but missing cloud platforms (Apple Books, Google Play).	Expand options and randomize order to reduce priming.
Q7 (comparative rating)	Subjective wording (“better”) may vary by interpretation.	Add anchor examples: “in terms of speed, usability, and relevance.”
Q8 (time-based scenario)	Good applied-context item; measures efficiency expectation.	Keep, but clarify: “If you had to find and purchase an e-book in under five minutes, how effective would this system be?”
4. Theoretical & Methodological Alignment

The questionnaire aligns with usability-testing principles but can be enhanced through:

Cognitive Pretesting: Ask 3–5 pilot respondents to verbalize interpretations to check clarity (per Wikipedia guidance).

Expert Review: Invite a usability researcher to assess ambiguity and construct coverage.

Bias Control: Randomize question order, alternate positive/negative phrasing, and add “Not applicable” options to all Likert items.

Scale Consistency: Use a uniform 5-point scale across all evaluative questions to simplify interpretation.

5. Overall Assessment
Criterion	Rating	Comment
Relevance to research aim	★★★★☆	Appropriate focus on usability, but needs better alignment of questions.
Clarity and neutrality		★★★☆☆	Some vague wording; lacks reverse items.
Structure and logic		★★★★☆	Logical flow, but branching not automated.
Validity and reliability	★★★☆☆	Can improve with cognitive pretesting and expert review.
6. Recommendations for Redesign

Refine scope: Exclude unnecessary financial questions unless they directly relate to usability.

Add behavioural indicators: e.g., “How often do you rely on recommendations rather than search?”

Include qualitative feedback: An open-ended final item such as “What is one improvement you would suggest for this system?”

Pilot test: Conduct a cognitive interview to ensure comprehension and identify redundant or confusing wording.

Visual consistency: Use a unified Likert grid and balanced layout for all rating questions.

7. Conclusion

The questionnaire demonstrates sound foundational design but requires refinement to enhance clarity, neutrality, and direct alignment with usability objectives. Applying cognitive pretesting, expert review, and bias control techniques will strengthen the instrument’s validity and reliability, ensuring that responses accurately reflect user perceptions of the e-book system.